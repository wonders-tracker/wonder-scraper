{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Floor Price Calculation: Approach Analysis\n",
    "\n",
    "This notebook investigates three different approaches to calculating floor prices:\n",
    "\n",
    "1. **SQL Floor** - Average of 4 lowest recent SALES\n",
    "2. **Lowest Ask** - Cheapest ACTIVE listing\n",
    "3. **Order Book Floor** - Deepest bucket from ACTIVE listings (OrderBookAnalyzer)\n",
    "\n",
    "## Goals\n",
    "- Compare floor estimates across cards with varying data quality\n",
    "- Identify when each approach is most accurate\n",
    "- Recommend a unified pricing strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from sqlmodel import Session, select, func, and_\n",
    "from app.db import engine\n",
    "from app.models import Card, MarketPrice, BlokpaxListing\n",
    "from app.services.order_book import OrderBookAnalyzer\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# First, let's check the data situation\nwith Session(engine) as session:\n    from datetime import datetime, timedelta, timezone\n    \n    today = datetime.now(timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0)\n    \n    print(\"=\" * 70)\n    print(\"DATA REALITY CHECK\")\n    print(\"=\" * 70)\n    \n    # Total counts\n    total_cards = session.execute(select(func.count(Card.id))).scalar()\n    total_active = session.execute(\n        select(func.count(MarketPrice.id)).where(MarketPrice.listing_type == 'active')\n    ).scalar()\n    \n    print(f\"\\nTotal Cards: {total_cards}\")\n    print(f\"Active Listings: {total_active:,}\")\n    \n    # Sales by week\n    print(\"\\nSales by Week (recent):\")\n    print(\"-\" * 40)\n    for weeks_ago in range(6):\n        start = today - timedelta(weeks=weeks_ago+1)\n        end = today - timedelta(weeks=weeks_ago)\n        count = session.execute(\n            select(func.count(MarketPrice.id)).where(\n                MarketPrice.listing_type == 'sold',\n                MarketPrice.sold_date >= start,\n                MarketPrice.sold_date < end,\n            )\n        ).scalar()\n        bar = '#' * min(count // 3, 30)\n        week_label = start.strftime('%b %d') + ' - ' + end.strftime('%b %d')\n        print(f\"  {week_label}: {count:4} {bar}\")\n    \n    # Cards with active listings\n    cards_active = session.execute(\n        select(func.count(func.distinct(MarketPrice.card_id)))\n        .where(MarketPrice.listing_type == 'active')\n    ).scalar()\n    print(f\"\\nCards with active listings: {cards_active} ({cards_active/total_cards*100:.1f}%)\")\n    \n    print(\"\\nâš ï¸  NOTE: Recent sales volume is low (holiday period).\")\n    print(\"    This makes SQL Floor less reliable than Order Book Floor.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Floor Calculation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_floor(session: Session, card_id: int, days: int = 30, treatment: str | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    SQL Floor: Average of 4 lowest recent SALES.\n",
    "    This is the current approach used in card list/detail views.\n",
    "    \"\"\"\n",
    "    cutoff = datetime.now(timezone.utc) - timedelta(days=days)\n",
    "    \n",
    "    filters = [\n",
    "        MarketPrice.card_id == card_id,\n",
    "        MarketPrice.listing_type == 'sold',\n",
    "        MarketPrice.price.isnot(None),\n",
    "        MarketPrice.sold_date >= cutoff,\n",
    "    ]\n",
    "    if treatment:\n",
    "        filters.append(MarketPrice.treatment == treatment)\n",
    "    \n",
    "    # Get 4 lowest sales\n",
    "    stmt = (\n",
    "        select(MarketPrice.price)\n",
    "        .where(and_(*filters))\n",
    "        .order_by(MarketPrice.price.asc())\n",
    "        .limit(4)\n",
    "    )\n",
    "    prices = [r for r in session.execute(stmt).scalars().all()]\n",
    "    \n",
    "    if not prices:\n",
    "        return {'floor': None, 'sample_size': 0, 'method': 'sql_floor'}\n",
    "    \n",
    "    return {\n",
    "        'floor': np.mean(prices),\n",
    "        'sample_size': len(prices),\n",
    "        'prices': prices,\n",
    "        'method': 'sql_floor'\n",
    "    }\n",
    "\n",
    "\n",
    "def get_lowest_ask(session: Session, card_id: int, treatment: str | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Lowest Ask: Cheapest ACTIVE listing.\n",
    "    Currently shown separately in card detail view.\n",
    "    \"\"\"\n",
    "    filters = [\n",
    "        MarketPrice.card_id == card_id,\n",
    "        MarketPrice.listing_type == 'active',\n",
    "        MarketPrice.price.isnot(None),\n",
    "    ]\n",
    "    if treatment:\n",
    "        filters.append(MarketPrice.treatment == treatment)\n",
    "    \n",
    "    stmt = (\n",
    "        select(func.min(MarketPrice.price), func.count(MarketPrice.id))\n",
    "        .where(and_(*filters))\n",
    "    )\n",
    "    result = session.execute(stmt).first()\n",
    "    \n",
    "    return {\n",
    "        'floor': result[0] if result else None,\n",
    "        'listing_count': result[1] if result else 0,\n",
    "        'method': 'lowest_ask'\n",
    "    }\n",
    "\n",
    "\n",
    "def get_order_book_floor(session: Session, card_id: int, days: int = 30, treatment: str | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Order Book Floor: Deepest bucket from ACTIVE listings.\n",
    "    Uses OrderBookAnalyzer with adaptive bucketing.\n",
    "    \"\"\"\n",
    "    analyzer = OrderBookAnalyzer(session)\n",
    "    result = analyzer.estimate_floor(card_id=card_id, treatment=treatment, days=days)\n",
    "    \n",
    "    if not result:\n",
    "        return {'floor': None, 'confidence': 0, 'method': 'order_book'}\n",
    "    \n",
    "    return {\n",
    "        'floor': result.floor_estimate,\n",
    "        'confidence': result.confidence,\n",
    "        'source': result.source,\n",
    "        'total_listings': result.total_listings,\n",
    "        'deepest_bucket': result.deepest_bucket,\n",
    "        'method': 'order_book'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample Cards with Varying Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session(engine) as session:\n",
    "    # Get cards with sales counts for stratified sampling\n",
    "    cutoff = datetime.now(timezone.utc) - timedelta(days=30)\n",
    "    \n",
    "    stmt = (\n",
    "        select(\n",
    "            Card.id,\n",
    "            Card.name,\n",
    "            Card.rarity,\n",
    "            func.count(MarketPrice.id).filter(\n",
    "                and_(MarketPrice.listing_type == 'sold', MarketPrice.sold_date >= cutoff)\n",
    "            ).label('sales_30d'),\n",
    "            func.count(MarketPrice.id).filter(\n",
    "                MarketPrice.listing_type == 'active'\n",
    "            ).label('active_listings'),\n",
    "        )\n",
    "        .join(MarketPrice, Card.id == MarketPrice.card_id, isouter=True)\n",
    "        .group_by(Card.id, Card.name, Card.rarity)\n",
    "        .order_by(func.count(MarketPrice.id).desc())\n",
    "    )\n",
    "    \n",
    "    results = session.execute(stmt).all()\n",
    "    card_df = pd.DataFrame(results, columns=['card_id', 'name', 'rarity', 'sales_30d', 'active_listings'])\n",
    "\n",
    "print(f\"Total cards: {len(card_df)}\")\n",
    "print(f\"\\nCards by data quality:\")\n",
    "print(f\"  High data (>=10 sales, >=5 active): {len(card_df[(card_df.sales_30d >= 10) & (card_df.active_listings >= 5)])}\")\n",
    "print(f\"  Medium data (5-9 sales, 2-4 active): {len(card_df[(card_df.sales_30d.between(5, 9)) & (card_df.active_listings.between(2, 4))])}\")\n",
    "print(f\"  Low data (<5 sales OR <2 active): {len(card_df[(card_df.sales_30d < 5) | (card_df.active_listings < 2)])}\")\n",
    "\n",
    "card_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare Floor Calculations Across Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select sample cards from each data quality tier\n",
    "high_data = card_df[(card_df.sales_30d >= 10) & (card_df.active_listings >= 5)].head(5)\n",
    "medium_data = card_df[(card_df.sales_30d.between(3, 9)) & (card_df.active_listings >= 2)].head(5)\n",
    "low_data = card_df[(card_df.sales_30d < 3) | (card_df.active_listings < 2)].head(5)\n",
    "\n",
    "sample_cards = pd.concat([high_data, medium_data, low_data]).drop_duplicates()\n",
    "print(f\"Analyzing {len(sample_cards)} sample cards...\")\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "with Session(engine) as session:\n",
    "    for _, row in sample_cards.iterrows():\n",
    "        card_id = int(row['card_id'])\n",
    "        \n",
    "        sql_floor = get_sql_floor(session, card_id)\n",
    "        lowest_ask = get_lowest_ask(session, card_id)\n",
    "        order_book = get_order_book_floor(session, card_id)\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'card_id': card_id,\n",
    "            'name': row['name'],\n",
    "            'rarity': row['rarity'],\n",
    "            'sales_30d': row['sales_30d'],\n",
    "            'active_listings': row['active_listings'],\n",
    "            # SQL Floor\n",
    "            'sql_floor': sql_floor['floor'],\n",
    "            'sql_sample': sql_floor['sample_size'],\n",
    "            # Lowest Ask\n",
    "            'lowest_ask': lowest_ask['floor'],\n",
    "            'ask_count': lowest_ask['listing_count'],\n",
    "            # Order Book\n",
    "            'ob_floor': order_book['floor'],\n",
    "            'ob_confidence': order_book.get('confidence', 0),\n",
    "            'ob_source': order_book.get('source', 'N/A'),\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Differences Between Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate differences between approaches\n",
    "df = comparison_df.copy()\n",
    "\n",
    "# Difference: SQL Floor vs Order Book\n",
    "df['sql_vs_ob'] = df['sql_floor'] - df['ob_floor']\n",
    "df['sql_vs_ob_pct'] = ((df['sql_floor'] - df['ob_floor']) / df['ob_floor'] * 100).round(1)\n",
    "\n",
    "# Difference: Lowest Ask vs Order Book\n",
    "df['ask_vs_ob'] = df['lowest_ask'] - df['ob_floor']\n",
    "df['ask_vs_ob_pct'] = ((df['lowest_ask'] - df['ob_floor']) / df['ob_floor'] * 100).round(1)\n",
    "\n",
    "# Difference: SQL Floor vs Lowest Ask\n",
    "df['sql_vs_ask'] = df['sql_floor'] - df['lowest_ask']\n",
    "df['sql_vs_ask_pct'] = ((df['sql_floor'] - df['lowest_ask']) / df['lowest_ask'] * 100).round(1)\n",
    "\n",
    "print(\"Price Differences Analysis:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nSQL Floor vs Order Book Floor:\")\n",
    "print(f\"  Mean difference: ${df['sql_vs_ob'].mean():.2f} ({df['sql_vs_ob_pct'].mean():.1f}%)\")\n",
    "print(f\"  Median difference: ${df['sql_vs_ob'].median():.2f}\")\n",
    "\n",
    "print(f\"\\nLowest Ask vs Order Book Floor:\")\n",
    "print(f\"  Mean difference: ${df['ask_vs_ob'].mean():.2f} ({df['ask_vs_ob_pct'].mean():.1f}%)\")\n",
    "print(f\"  Median difference: ${df['ask_vs_ob'].median():.2f}\")\n",
    "\n",
    "print(f\"\\nSQL Floor vs Lowest Ask:\")\n",
    "print(f\"  Mean difference: ${df['sql_vs_ask'].mean():.2f} ({df['sql_vs_ask_pct'].mean():.1f}%)\")\n",
    "print(f\"  Median difference: ${df['sql_vs_ask'].median():.2f}\")\n",
    "\n",
    "df[['name', 'sql_floor', 'lowest_ask', 'ob_floor', 'ob_confidence', 'sql_vs_ob_pct', 'ask_vs_ob_pct']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. When Does Each Approach Work Best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"APPROACH ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nğŸ“Š SQL FLOOR (Avg of 4 lowest sales)\")\n",
    "print(\"-\"*40)\n",
    "print(\"âœ… Pros:\")\n",
    "print(\"   - Based on ACTUAL transactions (real market clearing price)\")\n",
    "print(\"   - Less susceptible to outlier listings\")\n",
    "print(\"   - Works when no active listings exist\")\n",
    "print(\"âŒ Cons:\")\n",
    "print(\"   - Backward-looking (stale in fast-moving markets)\")\n",
    "print(\"   - Requires 4+ sales for accurate average\")\n",
    "print(\"   - Can be skewed by sniped/auction deals\")\n",
    "\n",
    "print(\"\\nğŸ“‹ LOWEST ASK (Cheapest active listing)\")\n",
    "print(\"-\"*40)\n",
    "print(\"âœ… Pros:\")\n",
    "print(\"   - Most current price signal\")\n",
    "print(\"   - What a buyer would actually pay right now\")\n",
    "print(\"   - Simple and intuitive\")\n",
    "print(\"âŒ Cons:\")\n",
    "print(\"   - Single outlier can distort (mispriced listing)\")\n",
    "print(\"   - Doesn't account for listing depth\")\n",
    "print(\"   - May be unrealistic (damaged, incomplete, etc.)\")\n",
    "\n",
    "print(\"\\nğŸ“ˆ ORDER BOOK FLOOR (Deepest bucket)\")\n",
    "print(\"-\"*40)\n",
    "print(\"âœ… Pros:\")\n",
    "print(\"   - Considers DEPTH (where most liquidity sits)\")\n",
    "print(\"   - Filters outliers via bucketing\")\n",
    "print(\"   - Includes confidence score\")\n",
    "print(\"   - Better represents 'true' floor with liquidity\")\n",
    "print(\"âŒ Cons:\")\n",
    "print(\"   - Requires sufficient active listings\")\n",
    "print(\"   - Falls back to sales when no listings\")\n",
    "print(\"   - Bucket boundaries can be arbitrary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Recommendation: Hybrid Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hybrid_floor(\n",
    "    session: Session,\n",
    "    card_id: int,\n",
    "    days: int = 30,\n",
    "    treatment: str | None = None,\n",
    "    confidence_threshold: float = 0.5,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Hybrid Floor: Use Order Book when confident, fall back to SQL Floor.\n",
    "    \n",
    "    Logic:\n",
    "    1. If Order Book confidence >= threshold: use Order Book floor\n",
    "    2. Else: use SQL floor (avg of 4 lowest sales)\n",
    "    3. Always show Lowest Ask separately as \"buy now\" price\n",
    "    \"\"\"\n",
    "    order_book = get_order_book_floor(session, card_id, days, treatment)\n",
    "    sql_floor = get_sql_floor(session, card_id, days, treatment)\n",
    "    lowest_ask = get_lowest_ask(session, card_id, treatment)\n",
    "    \n",
    "    # Decision logic\n",
    "    if order_book['floor'] is not None and order_book.get('confidence', 0) >= confidence_threshold:\n",
    "        primary_floor = order_book['floor']\n",
    "        primary_source = 'order_book'\n",
    "        primary_confidence = order_book['confidence']\n",
    "    elif sql_floor['floor'] is not None:\n",
    "        primary_floor = sql_floor['floor']\n",
    "        primary_source = 'sql_floor'\n",
    "        primary_confidence = min(0.4, sql_floor['sample_size'] / 4 * 0.4)  # Max 0.4 for SQL\n",
    "    else:\n",
    "        primary_floor = lowest_ask['floor']\n",
    "        primary_source = 'lowest_ask'\n",
    "        primary_confidence = 0.2  # Low confidence for single listing\n",
    "    \n",
    "    return {\n",
    "        'floor': primary_floor,\n",
    "        'source': primary_source,\n",
    "        'confidence': primary_confidence,\n",
    "        'lowest_ask': lowest_ask['floor'],\n",
    "        'all_estimates': {\n",
    "            'order_book': order_book,\n",
    "            'sql_floor': sql_floor,\n",
    "            'lowest_ask': lowest_ask,\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "# Test hybrid approach on sample cards\n",
    "print(\"HYBRID FLOOR RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "hybrid_data = []\n",
    "with Session(engine) as session:\n",
    "    for _, row in sample_cards.iterrows():\n",
    "        card_id = int(row['card_id'])\n",
    "        result = get_hybrid_floor(session, card_id, confidence_threshold=0.5)\n",
    "        \n",
    "        hybrid_data.append({\n",
    "            'name': row['name'][:25],\n",
    "            'hybrid_floor': result['floor'],\n",
    "            'source': result['source'],\n",
    "            'confidence': result['confidence'],\n",
    "            'lowest_ask': result['lowest_ask'],\n",
    "        })\n",
    "\n",
    "hybrid_df = pd.DataFrame(hybrid_data)\n",
    "print(hybrid_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n\\nSource distribution:\")\n",
    "print(hybrid_df['source'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Deep Dive: Treatment-Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a high-volume card for treatment analysis\n",
    "target_card = sample_cards[sample_cards.sales_30d == sample_cards.sales_30d.max()].iloc[0]\n",
    "print(f\"Analyzing: {target_card['name']} (ID: {target_card['card_id']})\")\n",
    "print(f\"Data: {target_card['sales_30d']} sales, {target_card['active_listings']} active listings\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "treatments = ['Classic Paper', 'Classic Foil', 'Stonefoil', 'Formless Foil', 'Prerelease', 'Promo']\n",
    "\n",
    "treatment_data = []\n",
    "with Session(engine) as session:\n",
    "    for treatment in treatments:\n",
    "        hybrid = get_hybrid_floor(session, int(target_card['card_id']), treatment=treatment)\n",
    "        \n",
    "        treatment_data.append({\n",
    "            'treatment': treatment,\n",
    "            'hybrid_floor': hybrid['floor'],\n",
    "            'source': hybrid['source'],\n",
    "            'confidence': hybrid['confidence'],\n",
    "            'lowest_ask': hybrid['lowest_ask'],\n",
    "            'ob_floor': hybrid['all_estimates']['order_book']['floor'],\n",
    "            'sql_floor': hybrid['all_estimates']['sql_floor']['floor'],\n",
    "        })\n",
    "\n",
    "treatment_df = pd.DataFrame(treatment_data)\n",
    "print(\"\\nFloor by Treatment (Hybrid Approach):\")\n",
    "print(treatment_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                        FLOOR PRICE RECOMMENDATIONS                          â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                                                                              â•‘\n",
    "â•‘  OPTION A: Keep Separate (Current State)                                    â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â•‘\n",
    "â•‘  â€¢ SQL Floor shown in card list/detail (\"Floor: $X\")                        â•‘\n",
    "â•‘  â€¢ Order Book Floor shown separately with confidence                         â•‘\n",
    "â•‘  â€¢ Lowest Ask shown as \"Buy Now\" price                                       â•‘\n",
    "â•‘  PRO: No changes needed, users see all data points                          â•‘\n",
    "â•‘  CON: Confusing - which floor is \"real\"?                                    â•‘\n",
    "â•‘                                                                              â•‘\n",
    "â•‘  OPTION B: Replace with Order Book                                           â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â•‘\n",
    "â•‘  â€¢ Use Order Book floor as primary                                           â•‘\n",
    "â•‘  â€¢ Fall back to SQL floor when confidence < 50%                             â•‘\n",
    "â•‘  â€¢ Always show confidence indicator                                          â•‘\n",
    "â•‘  PRO: Single source of truth, forward-looking                               â•‘\n",
    "â•‘  CON: Requires sufficient active listings, more complex                      â•‘\n",
    "â•‘                                                                              â•‘\n",
    "â•‘  OPTION C: Hybrid (RECOMMENDED)                                              â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â•‘\n",
    "â•‘  â€¢ PRIMARY: Order Book floor when confidence >= 50%                         â•‘\n",
    "â•‘  â€¢ FALLBACK: SQL floor when low confidence                                  â•‘\n",
    "â•‘  â€¢ SEPARATE: Lowest Ask always shown as \"instant buy\"                       â•‘\n",
    "â•‘  â€¢ TRANSPARENT: Show source and confidence                                   â•‘\n",
    "â•‘                                                                              â•‘\n",
    "â•‘  Implementation:                                                             â•‘\n",
    "â•‘    1. Create unified get_floor() function                                   â•‘\n",
    "â•‘    2. Update card API to use hybrid                                         â•‘\n",
    "â•‘    3. UI shows: \"Floor: $X.XX (85% conf)\" + \"Buy Now: $Y.YY\"                â•‘\n",
    "â•‘    4. Tooltip explains data source                                          â•‘\n",
    "â•‘                                                                              â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation sketch for hybrid floor\n",
    "print(\"\"\"\n",
    "IMPLEMENTATION SKETCH: Unified Floor Service\n",
    "============================================\n",
    "\n",
    "```python\n",
    "# app/services/floor_pricing.py\n",
    "\n",
    "class FloorPricingService:\n",
    "    def __init__(self, session: Session):\n",
    "        self.session = session\n",
    "        self.order_book = OrderBookAnalyzer(session)\n",
    "    \n",
    "    def get_floor(\n",
    "        self,\n",
    "        card_id: int,\n",
    "        treatment: str | None = None,\n",
    "        days: int = 30,\n",
    "    ) -> FloorEstimate:\n",
    "        # 1. Try Order Book first\n",
    "        ob_result = self.order_book.estimate_floor(card_id, treatment, days)\n",
    "        \n",
    "        if ob_result and ob_result.confidence >= 0.5:\n",
    "            return FloorEstimate(\n",
    "                floor=ob_result.floor_estimate,\n",
    "                confidence=ob_result.confidence,\n",
    "                source='order_book',\n",
    "                depth=ob_result.total_listings,\n",
    "            )\n",
    "        \n",
    "        # 2. Fall back to SQL floor\n",
    "        sql_floor = self._get_sql_floor(card_id, treatment, days)\n",
    "        if sql_floor:\n",
    "            return FloorEstimate(\n",
    "                floor=sql_floor,\n",
    "                confidence=0.4,  # Lower confidence for historical\n",
    "                source='sales_history',\n",
    "            )\n",
    "        \n",
    "        # 3. Last resort: lowest ask\n",
    "        lowest = self._get_lowest_ask(card_id, treatment)\n",
    "        return FloorEstimate(\n",
    "            floor=lowest,\n",
    "            confidence=0.2,\n",
    "            source='single_listing',\n",
    "        )\n",
    "```\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}